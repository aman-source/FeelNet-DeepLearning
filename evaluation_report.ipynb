{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Classification Model Comparison\n",
    "\n",
    "## 1. Logistic Regression Performance  \n",
    "```\n",
    "      precision    recall  f1-score   support\n",
    "\n",
    "       anger       0.89      0.81      0.85       275  \n",
    "        fear       0.88      0.81      0.84       224  \n",
    "         joy       0.85      0.95      0.90       695  \n",
    "        love       0.80      0.66      0.72       159  \n",
    "     sadness       0.90      0.93      0.92       581  \n",
    "    surprise       0.95      0.53      0.68        66  \n",
    "\n",
    "    accuracy                           0.87      2000  \n",
    "   macro avg       0.88      0.78      0.82      2000  \n",
    "weighted avg       0.87      0.87      0.87      2000  \n",
    "```\n",
    "### Summary:\n",
    "- Overall Accuracy: 87%  \n",
    "- Performs well on all emotions, but surprise has low recall (53%).  \n",
    "- Best for a lightweight, interpretable baseline model.  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. CNN Performance  \n",
    "```\n",
    "      precision    recall  f1-score   support\n",
    "\n",
    "       anger       0.89      0.92      0.91       275  \n",
    "        fear       0.92      0.86      0.89       224  \n",
    "         joy       0.94      0.93      0.93       695  \n",
    "        love       0.78      0.81      0.79       159  \n",
    "     sadness       0.94      0.96      0.95       581  \n",
    "    surprise       0.78      0.77      0.78        66  \n",
    "\n",
    "    accuracy                           0.91      2000  \n",
    "   macro avg       0.88      0.87      0.87      2000  \n",
    "weighted avg       0.91      0.91      0.91      2000  \n",
    "```\n",
    "### Summary:\n",
    "- Overall Accuracy: 91%  \n",
    "- Best performing model.  \n",
    "- Highest F1-score on almost all emotions.  \n",
    "- Handles surprise better than Logistic Regression.  \n",
    "---\n",
    "\n",
    "## 3. LSTM Performance  \n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       anger       0.00      0.00      0.00       275  \n",
    "        fear       0.00      0.00      0.00       224  \n",
    "         joy       0.35      1.00      0.52       695  \n",
    "        love       0.00      0.00      0.00       159  \n",
    "     sadness       0.00      0.00      0.00       581  \n",
    "    surprise       0.00      0.00      0.00        66  \n",
    "\n",
    "    accuracy                           0.35      2000  \n",
    "   macro avg       0.06      0.17      0.09      2000  \n",
    "weighted avg       0.12      0.35      0.18      2000  \n",
    "```\n",
    "### Summary:\n",
    "- Overall Accuracy: 35% (Very Low).  \n",
    "- Only recognizes joy; fails on all other emotions.  \n",
    "- Model likely overfitting or improperly trained.  \n",
    "\n",
    "---\n",
    "\n",
    "## Final Comparison Table  \n",
    "| Model                | Accuracy | Best Emotion | Worst Emotion | Recommended For |\n",
    "|----------------------|----------|--------------|--------------|----------------|\n",
    "| Logistic Regression | 87%  | Joy, Sadness  | Surprise (53%) | Fast, interpretable baseline |\n",
    "| CNN                 | 91%  | All emotions   | None (balanced) | Best overall model |\n",
    "| LSTM                | 35%  | Joy (overfit)  | Everything else | Needs fixing (not usable) |\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion and Next Steps  \n",
    "- CNN is the best model (91% accuracy) and should be used for deployment.  \n",
    "- LSTM is underperforming and needs debugging (likely overfitting or bad hyperparameters).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
